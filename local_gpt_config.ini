seq-len = 128
batch-size = 4
val-interval = 100
d-model = 64
heads = 4
n-layer = 2

learning-rate = 5.e-4
min-learning-rate = 1.e-6
warmup-iters = 7000
lr-decay-iters = 13000
max-iters = 15000

# dataset-pattern = train_gpt.wiki.2.20_*.msgpack
# val-dataset-pattern = val_gpt.wiki.2.20_*.msgpack
# test-dataset-pattern = test_gpt.wiki.2.20_*.msgpack

