{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import msgpack\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ron/dev/torch/medium'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "project_dir = Path('/Users/ron/dev/torch/medium')\n",
    "os.chdir(project_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index, order_id, product_id\n",
    "order_list = pd.read_csv('./data/instacart/order_list.csv', header=0, index_col=0)\n",
    "\n",
    "# Convert 'product_id' from string to list\n",
    "order_list['product_id'] = order_list['product_id'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets frequency of each product_id. This determines the order of the products in the vecabulary\n",
    "product_ids = [product_id for sublist in order_list['product_id'].tolist() for product_id in sublist]\n",
    "counts = Counter(product_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort first by counts in descending order and then by product id in ascending order\n",
    "sorted_counts = sorted(counts.items(), key=lambda x: (-x[1], x[0]))\n",
    "SPECIAL_TOKENS = ['<PAD>', '<UNK>', '<CLS>', '<SEP>', '<MASK>']\n",
    "vocab_path = Path('./vocab') / 'instacart_vocab.txt'\n",
    "vocab = SPECIAL_TOKENS + [product_id for product_id, _ in sorted_counts]\n",
    "with open(vocab_path, 'x') as f:\n",
    "    f.write('\\n'.join(map(str, vocab)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocab\n",
    "# create product_id to token_id mapping\n",
    "# create a toekn_id to product_name mapping\n",
    "# translate the product_id lists to token_id lists\n",
    "# create an MLM dataset from the lists by masking 15% of the tokens\n",
    "# split the dataset into train, validation and test sets\n",
    "\n",
    "# load vocab.txt into a list of tokens\n",
    "with open(vocab_path, 'r') as f:\n",
    "    vocab = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build product_id to token_id mapping\n",
    "# we'll use it to convert the product_id lists of orders to token_id lists\n",
    "product_id_to_token_id = {}\n",
    "for token_id, product_id in enumerate(vocab):\n",
    "    if token_id < 5:\n",
    "        continue\n",
    "    product_id_to_token_id[int(product_id)] = token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24852, 5), (13176, 6), (21137, 7), (21903, 8), (47209, 9)]\n",
      "[24852, 13176, 21137, 21903, 47209]\n",
      "[5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(list(product_id_to_token_id.items())[:5])\n",
    "print(list(product_id_to_token_id.keys())[:5])\n",
    "print(list(product_id_to_token_id.values())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_msgpack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2r/l2c74bh14fb4trl792dpdxbc0000gp/T/ipykernel_3718/4205476044.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;31m# convert product_id lists to token_id lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0morder_token_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0morder_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_id_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0morder_token_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_id_to_token_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproduct_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mproduct_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct_id_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_msgpack'"
     ]
    }
   ],
   "source": [
    "# convert product_id lists to token_id lists\n",
    "order_token_list = {}\n",
    "for order_id, product_id_list in order_list['product_id'].items():\n",
    "    order_token_list[order_id] = [int(product_id_to_token_id[product_id]) for product_id in product_id_list]\n",
    "\n",
    "# create a dataframe\n",
    "order_token_list_df = pd.DataFrame(list(order_token_list.items()), columns=['order_id', 'token_id'])\n",
    "\n",
    "# convert the token_id column to a string\n",
    "order_token_list_df['token_id'] = order_token_list_df['token_id'].apply(lambda x: str(x))\n",
    "\n",
    "# save to csv\n",
    "order_token_list_df.to_csv('./data/instacart/order_token_list.csv', index=False)\n",
    "\n",
    "order_token_list_df.to_msgpack('./data/instacart/order_token_list.msgpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a token_id to product_name mapping\n",
    "products = pd.read_csv('products.csv', header=0)\n",
    "# convert product_id to int\n",
    "products['product_id'] = products['product_id'].astype(int)\n",
    "# filter by only products that are in the order_list\n",
    "products = products.set_index('product_id').loc[product_id_to_token_id.keys()].reset_index()\n",
    "\n",
    "# create token_id to product_name mapping\n",
    "token_id_to_product_name = {}\n",
    "for product_id, product_name in products[['product_id', 'product_name']].values:\n",
    "    token_id = product_id_to_token_id[product_id]\n",
    "    token_id_to_product_name[token_id] = product_name\n",
    "df = pd.DataFrame.from_dict(token_id_to_product_name, orient='index', columns=['product_name'])\n",
    "df.index.name = 'token_id'\n",
    "df.to_csv('token_id_to_product_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.214874e+06\n",
       "mean     1.008888e+01\n",
       "std      7.525398e+00\n",
       "min      1.000000e+00\n",
       "25%      5.000000e+00\n",
       "50%      8.000000e+00\n",
       "75%      1.400000e+01\n",
       "max      1.450000e+02\n",
       "Name: product_id, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_list.product_id.apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
