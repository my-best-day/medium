# This is a template configuration file for the training script.
# Copy this file to <project-base>/config.ini and modify the values as needed
seq-len = 128
batch-size = 100
val-interval = 100
d-model = 768
heads = 12
n-layer = 6
dropout = 0.3

async-to-device: true
fused-adamw: true
compile: true

learning-rate = 1e-3
min-learning-rate = 1e-4
warmup-iters = 1000
lr-decay-iters = 25_000
max-iters = 25_000
weight-decay = 0.01

# lr-scheduler = steplr:10:0.7
base-dir = wiki
case = dickens
dataset-pattern = train_wiki_*.msgpack
val-dataset-pattern = val_wiki_*.msgpack
dist-master-addr = 127.0.0.1
dist-master-port = 12233
max-checkpoints = 1
wandb = false
